{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DLA2Try1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DwHXXp1pwuEz",
        "colab_type": "text"
      },
      "source": [
        "# Large Movie Review Dataset Sentiment Analysis\n",
        "\n",
        "The IMDB Movie review dataset is for binary sentiment classification containing substantially more data than previous benchmark datasets. It has  \n",
        "\n",
        "*   50,000 reviews with 25,000 positive reviews & 25000, negative reviews\n",
        "*   A total of 108848 distinct words in the corpus\n",
        "*   An average of 231 words per review\n",
        "*   Biggest review with 2470 words and smallest review with 4 words\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55AO62YZ1j9Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load all the required py modules\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import nltk\n",
        "\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score,confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "%tensorflow_version 1.x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYHz3Etx9Ql5",
        "colab_type": "code",
        "outputId": "b33f0d44-e493-453e-f71f-1d4fea3022e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "# Download the punkt package for tokenizing\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcLxJfidacSK",
        "colab_type": "text"
      },
      "source": [
        "## Naive Bayes Classifier using SKLearn\n",
        "\n",
        "We will establish a benchmark accuracy using Naive bayes which our neural network will try to beat . Naive Bayes methods are a set of supervised learning algorithms based on applying Bayes’ theorem with the “naive” assumption of conditional independence between every pair of features given the value of the class variable.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvlYCVHo40xh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Read in aggregated dataset\n",
        "df = pd.read_csv('IMDB Dataset.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSvvlKx945tJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#tokenize the reviews\n",
        "tokeniser = CountVectorizer( tokenizer=nltk.word_tokenize)\n",
        "\n",
        "# Encode 'Positive' & 'Negative' classes to 1 & 0\n",
        "encoder = LabelEncoder()\n",
        "oneHotEncoder = OneHotEncoder()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7TbopHL_9q0O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use 75 % of the reviews for training and test on 25%\n",
        "X_train,X_test,Y_train,Y_test = train_test_split(df.review, df.sentiment ,random_state = 32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSDr5xx2985l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# reviews to tokenized form\n",
        "X_train_vec = tokeniser.fit_transform(X_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fO3RnsR5LSVO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 1,0 encoded classes\n",
        "Y_train_enc = encoder.fit_transform(Y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9m36L9kf-wKs",
        "colab_type": "code",
        "outputId": "13835a93-195b-4423-c4e1-fe796b73e791",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#Train\n",
        "clf = MultinomialNB()\n",
        "clf.fit(X_train_vec, Y_train_enc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2Yu1yfS--je",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Test\n",
        "X_test_vec = tokeniser.transform(X_test)\n",
        "Y_test_enc = encoder.transform(Y_test)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Px1JlgzU_QBJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_predicted = clf.predict(X_test_vec)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGCk503d_Y5v",
        "colab_type": "code",
        "outputId": "e98de741-d5e6-49a7-bc28-670973eef913",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "accuracy_score(Y_test_enc,y_predicted)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8408"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6AA6VVM_p82",
        "colab_type": "code",
        "outputId": "124d4536-35be-4e2d-bb9f-23f94b8e011a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "print(classification_report(Y_test_enc,y_predicted))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.87      0.84      6169\n",
            "           1       0.87      0.81      0.84      6331\n",
            "\n",
            "    accuracy                           0.84     12500\n",
            "   macro avg       0.84      0.84      0.84     12500\n",
            "weighted avg       0.84      0.84      0.84     12500\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9fBQUwDZsFM",
        "colab_type": "text"
      },
      "source": [
        "## LSTM Implementation using Keras & Tensorflow\n",
        "\n",
        "Our choice of Neural Networks is Long Short-Term Memory networks (LSTM). LSTM’s are a special case of Recurrent Neural Networks (RNN) which has the capability of learning long-term dependencies. \n",
        "\n",
        "![LSTM architecture](https://i.stack.imgur.com/voZql.jpg)\n",
        "\n",
        "### Justification for using LSTM\n",
        "\n",
        "* LSTM networks don’t suffer from the vanishing gradient problem unlike RNNs\n",
        "* They can hold on to long term dependencies. The presence of many words in the review might have alter its meaning. LSTM can handle this scenario well.\n",
        "* Contains memory cell that can hold information for long period of time.\n",
        "* Gates at input, forget and output layers can be controlled to manage the information in a single LSTM cell.\n",
        "* Like RNN, LSTM can also handle sequences of data points."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9uWwMd5KYXu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.python.keras.preprocessing import sequence\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRXaa8tC_vuU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Model\n",
        "from keras.utils import to_categorical\n",
        "from keras.wrappers.scikit_learn import KerasRegressor\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Input, Dense, Dropout, Embedding, Flatten, LSTM\n",
        "from keras import optimizers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFHjlThkMaMr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('IMDB Dataset.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQ_1MFy4Mdhk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train,X_test,Y_train,Y_test = train_test_split(df.review, df.sentiment ,random_state = 32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uuJXJm590Xvp",
        "colab_type": "text"
      },
      "source": [
        "## Word embeddings\n",
        "\n",
        "The reviews are not always of the same length. The input to a neural network needs to equal length vectors. So, \n",
        "\n",
        "* Keras’s tokeniser was used to tokenize the input reviews\n",
        "* All the reviews were cut off to a maximum number of 500 words\n",
        "* Reviews with less than 500 words were padded to get a uniform length\n",
        "* Words were converted to the word index in the vocabulary\n",
        "* A word embedded layer was utilized to reduce the 500-dimension word vectors to 100-dimension word vectors\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIsxV7f9KwAd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Tokenise the text\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(list(X_train))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4JoxzPCOYWw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_train_enc = encoder.fit_transform(Y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMUdV_-6RDhm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_test_enc = encoder.transform(Y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nvetq5e4Mori",
        "colab_type": "code",
        "outputId": "c2ae2dfe-751c-465b-9bca-f7fd35a39daf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# convert words to word in in vocabulary \n",
        "list_tokenized_train = tokenizer.texts_to_sequences(X_train)\n",
        "list_tokenized_test = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "#Total unique words \n",
        "print(len(tokenizer.word_index))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "108848\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4k0ebaFbLvkX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "maxlen = 500\n",
        "\n",
        "# This makes all reviews to be of size 500 Vector\n",
        "X_t = pad_sequences(list_tokenized_train, maxlen=maxlen)\n",
        "X_te = pad_sequences(list_tokenized_test, maxlen=maxlen)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2nm4aKyVOBJz",
        "colab_type": "code",
        "outputId": "1a02c9c7-e74c-4545-a40b-0aafa3867f0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "X_t.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(37500, 500)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_MWHWQdABcv",
        "colab_type": "code",
        "outputId": "fc6d5e15-0584-4732-8a21-dd6456ed0f27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        }
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "# Find embeddings for input to 100 dimensions\n",
        "model.add(Embedding(vocab_size, 100, input_length=maxlen))\n",
        "model.add(Dropout(0.5))\n",
        "# LSTM for sentiment classification\n",
        "model.add(LSTM(64))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['acc'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 500, 100)          10884900  \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 500, 100)          0         \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 64)                42240     \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 2)                 130       \n",
            "=================================================================\n",
            "Total params: 10,927,270\n",
            "Trainable params: 10,927,270\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Q0HXe1NCuHC",
        "colab_type": "code",
        "outputId": "929eb405-729e-4eb8-d48d-37f45cce337d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        }
      },
      "source": [
        "history = model.fit([X_t], batch_size=32, y=to_categorical(Y_train_enc), verbose=1, validation_split=0.25, \n",
        "          shuffle=True, epochs=3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 28125 samples, validate on 9375 samples\n",
            "Epoch 1/3\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "28125/28125 [==============================] - 557s 20ms/step - loss: 0.6340 - acc: 0.6472 - val_loss: 0.5518 - val_acc: 0.7333\n",
            "Epoch 2/3\n",
            "28125/28125 [==============================] - 558s 20ms/step - loss: 0.4141 - acc: 0.8180 - val_loss: 0.3299 - val_acc: 0.8580\n",
            "Epoch 3/3\n",
            "28125/28125 [==============================] - 556s 20ms/step - loss: 0.2299 - acc: 0.9158 - val_loss: 0.3110 - val_acc: 0.8843\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZXLLrSsEwv_",
        "colab_type": "code",
        "outputId": "a347406a-4929-4d3b-8289-6731a9e36198",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "\n",
        "predicted = model.predict(X_te)\n",
        "Y_predicted = np.argmax(predicted, axis=1)\n",
        "print (accuracy_score(Y_test_enc,Y_predicted))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.88136\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4iFh0psTAUr",
        "colab_type": "code",
        "outputId": "9c4dc18e-15c7-428e-8ebc-919d680f9a64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "print (classification_report(Y_test_enc,Y_predicted))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.92      0.88      6169\n",
            "           1       0.91      0.85      0.88      6331\n",
            "\n",
            "    accuracy                           0.88     12500\n",
            "   macro avg       0.88      0.88      0.88     12500\n",
            "weighted avg       0.88      0.88      0.88     12500\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slt7Jt39VKot",
        "colab_type": "code",
        "outputId": "ecb027f9-364d-4ebe-fc4a-ce83ed0252b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "# Plot Accuracy vs Epoch to show learning rate\n",
        "df_result = pd.DataFrame({'epochs':history.epoch, 'accuracy': history.history['acc'], 'validation_accuracy': history.history['val_acc']})\n",
        "g = sns.pointplot(x=\"epochs\", y=\"accuracy\", data=df_result, fit_reg=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n9P8BqKL9tUi1fVEAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGLEDh2nVtiD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_result.to_csv('EpochHistory.csv',index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6nuqAG4Ykpx",
        "colab_type": "text"
      },
      "source": [
        "Showing Incorrectly classified Reviews\n",
        "\n",
        "\n",
        "\n",
        "*   Find out all indices where our prediction & true label did not match (Logical XNOR )\n",
        "*   Sample the original Dataframe with these indices and dislay full reviews\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5JP0sv2_V3Oh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "incorrect_index = (~np.logical_xor(Y_test_enc,Y_predicted)).nonzero()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "woDctNclXP15",
        "colab_type": "code",
        "outputId": "c44efa93-bb8c-4205-cb2b-4b47952a5222",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 673
        }
      },
      "source": [
        "pd.set_option('display.max_colwidth', -1)\n",
        "df.iloc[incorrect_index].sample(5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5106</th>\n",
              "      <td>You'd have more excitement cutting off your testicles than watching this, clearly a trick to get you to rent \"Descent\" instead of \"The Descent\", which is a much better movie.&lt;br /&gt;&lt;br /&gt;This is a total rip off of \"The Core\" and much, much worse as regards special effects, I could do better with a box of cornflakes and a roll of tinfoil, I mean come on!....that \"Mole\" thing, bore more resemblance to a vibrating dildo than a subterranean vehicle .&lt;br /&gt;&lt;br /&gt;Don't watch it - if you do you'll find the room your in has a funny smell for days after and you'll have this nagging feeling in the back of your head that you should go kill yourself or something.</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1987</th>\n",
              "      <td>Gary Busey is superb in this musical biography. Great singing and excellent soundtrack. The Buddy Holly Story is a much better movie than La Bamba. From reading other comments, there may be some historical inaccuracies. Regardless, it is a fun toe-tapping film, and a good introduction to Buddy Holly's music.</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11798</th>\n",
              "      <td>Ghost Train is a fine and entertaining film, typical of the better British comedy chillers of the 1930s and 40s. The antics of comedian Arthur Askey are not as funny as they once apparently were, but this can be overcome by viewing him as a period piece or a curiosity.&lt;br /&gt;&lt;br /&gt;For a low-budget wartime production, Ghost Train is atmospheric, effective, and it provides some genuine suspense. Great fun for a dark (and, yes, stormy) night. Lighten up, take off the critic's hat, and enjoy.</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8697</th>\n",
              "      <td>Witty and disgusting. Brash and intelligent. BASEketball redefines comedy/sports with a pot spoof of an easy target. Makes other so called comedies like dead boring. One of the best of all time! Trey Parker and Matt Stone play their roles as losers with apt perfection.</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1213</th>\n",
              "      <td>being a high school student,i have to take a health class. this year, the topic is drugs. we learn about the harm they can cause a person. from what we talk about, i still believe and know that drugs can really mess a person up. anyway, my teacher wanted us to watch this. naturally, we groan and start to sleep, but like the rest of my class, i actually did enjoy this movie. it was totally real, and not sugar coated at all. the characters were amazing and believable. even the plot was outstandingly realistic and believable. what i liked about this movie mainly was how it got the point of the effect's drugs can take on an abuser, and the consequences the person has to deal with. everyone reassures themselves that nothing bad will happen to them. well lets get serious. anything can happen in a small town, even to your best friend, like Sam and Chris. this movie shows it. a person can really learn a lot from watching this. it was pretty effective.</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              review sentiment\n",
              "5106   You'd have more excitement cutting off your testicles than watching this, clearly a trick to get you to rent \"Descent\" instead of \"The Descent\", which is a much better movie.<br /><br />This is a total rip off of \"The Core\" and much, much worse as regards special effects, I could do better with a box of cornflakes and a roll of tinfoil, I mean come on!....that \"Mole\" thing, bore more resemblance to a vibrating dildo than a subterranean vehicle .<br /><br />Don't watch it - if you do you'll find the room your in has a funny smell for days after and you'll have this nagging feeling in the back of your head that you should go kill yourself or something.                                                                                                                                                                                                                                                                                                             negative\n",
              "1987   Gary Busey is superb in this musical biography. Great singing and excellent soundtrack. The Buddy Holly Story is a much better movie than La Bamba. From reading other comments, there may be some historical inaccuracies. Regardless, it is a fun toe-tapping film, and a good introduction to Buddy Holly's music.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          positive\n",
              "11798  Ghost Train is a fine and entertaining film, typical of the better British comedy chillers of the 1930s and 40s. The antics of comedian Arthur Askey are not as funny as they once apparently were, but this can be overcome by viewing him as a period piece or a curiosity.<br /><br />For a low-budget wartime production, Ghost Train is atmospheric, effective, and it provides some genuine suspense. Great fun for a dark (and, yes, stormy) night. Lighten up, take off the critic's hat, and enjoy.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   positive\n",
              "8697   Witty and disgusting. Brash and intelligent. BASEketball redefines comedy/sports with a pot spoof of an easy target. Makes other so called comedies like dead boring. One of the best of all time! Trey Parker and Matt Stone play their roles as losers with apt perfection.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  positive\n",
              "1213   being a high school student,i have to take a health class. this year, the topic is drugs. we learn about the harm they can cause a person. from what we talk about, i still believe and know that drugs can really mess a person up. anyway, my teacher wanted us to watch this. naturally, we groan and start to sleep, but like the rest of my class, i actually did enjoy this movie. it was totally real, and not sugar coated at all. the characters were amazing and believable. even the plot was outstandingly realistic and believable. what i liked about this movie mainly was how it got the point of the effect's drugs can take on an abuser, and the consequences the person has to deal with. everyone reassures themselves that nothing bad will happen to them. well lets get serious. anything can happen in a small town, even to your best friend, like Sam and Chris. this movie shows it. a person can really learn a lot from watching this. it was pretty effective.  positive"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtP9RONmyUNn",
        "colab_type": "text"
      },
      "source": [
        "## References\n",
        "\n",
        "#### Aggregated Dataset source\n",
        "\n",
        "* https://www.kaggle.com/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews\n",
        "* https://ai.stanford.edu/~amaas/data/sentiment/\n",
        "\n",
        "#### Scikit-learn Naïve Bayes Classifier Tutorial\n",
        "\n",
        "* https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html\n",
        "* https://scikit-learn.org/stable/modules/naive_bayes.html\n",
        "\n",
        "#### Word Embedding Tutorials\n",
        "\n",
        "* https://machinelearningmastery.com/use-word-embedding-layers-deep-learning-keras/\n",
        "* https://colab.research.google.com/github/pasumarthi/Backprop/blob/master/ADR_tweet_classifier_keras.ipynb\n",
        "\n",
        "\n",
        "\n",
        "#### LSTM Tutorials\n",
        "\n",
        "* https://colah.github.io/posts/2015-08-Understanding-LSTMs/\n",
        "* https://medium.com/@saurabh.rathor092/simple-rnn-vs-gru-vs-lstm-difference-lies-in-more-flexible-control-5f33e07b1e57\n",
        "\n",
        "#### Keras - LSTM sentiment analysis sources\n",
        "\n",
        "* https://www.kaggle.com/eriche523/bidirectional-lstm-in-keras\n",
        "* https://www.kaggle.com/khaledmgamal/bag-of-words-rnn-lstm-sentiment/notebook"
      ]
    }
  ]
}